{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattertext\n",
    "\n",
    "This notebook uses Jason Kessler's <a href=\"https://github.com/JasonKessler/scattertext\" target=\"_blank\">Scattertext</a> library to allow you to explore key terms in your corpus in relation to your documents' metadata.\n",
    "\n",
    "Note that for the purpose of working with Scattertext, the original text is re-tokenized using slightly different rules from the WE1S preprocessor, so there may be some small discrepancies. By default, the WE1S standard stoplist in your project's MALLET module is applied.\n",
    "\n",
    "### INFO\n",
    "\n",
    "__author__    = 'Scott Kleinman'  \n",
    "__copyright__ = 'copyright 2020, The WE1S Project'  \n",
    "__license__   = 'MIT'  \n",
    "__version__   = '0.9.1'  \n",
    "__email__     = 'scott.kleinman@csun.edu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "try:\n",
    "    import scattertext as st\n",
    "except ImportError:\n",
    "    !pip install scattertext\n",
    "    import scattertext as st\n",
    "\n",
    "# Get paths\n",
    "current_dir                = %pwd\n",
    "project_dir                = str(Path(current_dir).parent.parent)\n",
    "data_dir                   = project_dir + '/project_data'\n",
    "json_dir                   = data_dir + '/json'\n",
    "module_data_dir            = current_dir + '/data'\n",
    "topic_weights_script_path  = current_dir + '/' + 'scripts/topic_weights.py'\n",
    "scattertext_script_path    = current_dir + '/' + 'scripts/scattertext.py'\n",
    "stoplist_path              = project_dir + '/modules/topic_modeling/scripts/we1s_standard_stoplist.txt'\n",
    "\n",
    "# Import scripts\n",
    "%run {scattertext_script_path}\n",
    "\n",
    "# Output message\n",
    "display(HTML('<p style=\"color:green;font-weight:bold;\">Setup complete.</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents\n",
    "\n",
    "This cell loads the json documents for the entire collection. This can take a while. For experimentation, it is best to set `end` to a smaller number. For an explanaiton of the various configuration settings, see the <a href=\"README.md\" target=\"_blank\">README</a> file.\n",
    "\n",
    "If you have run this cell previously and wish to use the same settings, you can skip this cell. The next cell will load your Documents dataframe from a stored copy called `documents_df.parquet`. If you wish to save the settings, this fille will be overwritten with the new dataframe, so make a backup if you wish to keep the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "start            = 0\n",
    "end              = None # E.g. 2000\n",
    "extra_fields     = {} # E.g. {'date': 'pub_date', 'tags': 'tags'}\n",
    "random_sampling  = None # The percentage of the collection to sample or None\n",
    "use_file         = False\n",
    "\n",
    "if use_file:\n",
    "    try:\n",
    "        table = load_documents_df(module_data_dir, to_qgrid = True)\n",
    "    except IOError:\n",
    "        table = build_document_dataframe(json_dir, start, end, extra_fields, random_sampling)\n",
    "else:\n",
    "    table = build_document_dataframe(json_dir, start, end, extra_fields, random_sampling)\n",
    "    \n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Dataframe to CSV\n",
    "\n",
    "If you wish to save the dataframe to a CSV file, configure a filename and then uncomment one of the lines below. The first will save the original dataframe and the second will save the dataframe after any sorting or filtering you have done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "filename = 'table.csv'\n",
    "\n",
    "# Save the original dataframe\n",
    "# table.df.to_csv(filename)\n",
    "\n",
    "# Save the changed dataframe\n",
    "# table.get_changed_df().to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Document Counts Report\n",
    "\n",
    "This cell provides a table of document counts for each field column beginning with the one configured for the `start_column` value. The rows provide the document counts by _value_. This information will be used for configuring the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure start_column\n",
    "start_column = 4\n",
    "preview      = None\n",
    "\n",
    "generate_counts_report(table.df, start_column, preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Corpus\n",
    "\n",
    "When the corpus is built, each document is parsed using spaCy, so this can take a while. For that reason, it is a good idea to set the limit to around 2000 documents or smaller.\n",
    "\n",
    "Before generating the corpus, the cell will automatically look for a previously-saved corpus file to speed loading time. If you have changed your `limit` or `field` settings, change the name of the `corpus_file` or set `from_file=False`. If you do not change the name of `corpus_file`, any previous corpus with that filename will be overwritten. \n",
    "\n",
    "<p style=\"color:red;\">Important: A Scattertext corpus requires a <code>field</code> category corresponding to one of the column headings in the Document Counts Report above. The column must contain at least two non-zero. If you get an error, you may not have chosen a valid field.</p>\n",
    "\n",
    "Results seem to be improved by using lemmas rather than the original tokens, but this can be changed with `use_lemmas=False`. The other options are more unpredicatable. The `entity_types_to_use` and `tag_types_to_use` lists allow you to specify entity and part of speech categories that should be retained in the analysis. Tokens not belonging to the types you specify will be excluded from the corpus. A list of the category abbreviations can be found in the spaCy documentation for <a href=\"https://spacy.io/api/annotation#named-entities\" target=\"_blank\">named entities</a> and <a href=\"https://spacy.io/api/annotation#pos-universal\" target=\"_blank\">part of speech tags</a>. If you wish to use all the categories, set these values to `All`.\n",
    "\n",
    "You can also \"censor\" certain types, which replaces the original token it entity or part of speech abbreviation. Lastly, periods at the ends of tokens can be stripped if they have escaped spaCy's tokenizer.\n",
    "\n",
    "For convenience, here are list of all entity and part of speech abbreviations, which you can use to copy and paste into the cell below.\n",
    "\n",
    "### Named Entities\n",
    "\n",
    "<code>\"PERSON\", \"NORP\", \"FAC\", \"ORG\", \"GPE\", \"LOC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\", \"DATE\", \"TIME\", \"PERCENT\", \"MONEY\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\"</code>\n",
    "\n",
    "### Parts of Speech\n",
    "\n",
    "<code>\"$\", \"``\", \"''\", \",\", \"-LRB-\", \"-RRB-\", \".\", \":\", \"ADD\", \"CC\", \"CD\", \"DT\", \"EX\", \"IN\", \"LS\", \"NFP\", \"NIL\", \"NNP\", \"NNPS\", \"PDT\", \"POS\", \"PRP\", \"PRP$\", \"RP\", \"SYM\", \"TO\", \"UH\", \"WDT\", \"WP\", \"WP$\", \"WRB\"</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "limit                   = 2000 # Less than or equal to the `end` value in Load Documents\n",
    "field                   = '' # Eg. 'funding'\n",
    "corpus_file             = '' # E.g. 'corpus' -- No extension necessary\n",
    "from_file               = True\n",
    "stoplist_path           = stoplist_path\n",
    "use_lemmas              = True\n",
    "entity_types_to_use     = None # E.g. [\"PERSON\", \"NORP\", \"FAC\", \"ORG\", \"GPE\", \"LOC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\"]\n",
    "entity_types_to_censor  = [] # E.g. [\"PERSON\", \"NORP\", \"FAC\", \"ORG\", \"GPE\", \"LOC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\"]\n",
    "tag_types_to_use        = None # E.g. [\"AFX\", \"NN\", \"NNS\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"VB\", \"VBD\", \"VBF\", \"VBN\", \"VBP\", \"VBZ\"]\n",
    "tag_types_to_censor     = [] # E.g. [\"NNP\", \"NNPS\"]\n",
    "strip_final_period      = False\n",
    "\n",
    "if not isinstance(df, pd.DataFrame):\n",
    "    df = load_documents_df(module_data_dir)\n",
    "if from_file is True:\n",
    "    corpus = load_corpus(module_data_dir, corpus_file)\n",
    "    display(HTML('<p style=\"color:green;\">Corpus loaded from file.</p>'))\n",
    "if corpus is None or from_file is False:\n",
    "    corpus = generate_corpus(module_data_dir, corpus_file, nlp, df.head(limit), field, stoplist_path=stoplist_path,\n",
    "                             use_lemmas=use_lemmas, entity_types_to_use=entity_types_to_use, tag_types_to_use=tag_types_to_use, \n",
    "                             entity_types_to_censor=entity_types_to_censor, tag_types_to_censor=tag_types_to_censor,\n",
    "                             strip_final_period=strip_final_period)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate terms that differentiate the collection from a general English corpus\n",
    "\n",
    "Note: We _think_ that Scattertext is using the Brown Corpus for comparison, but we have not been able to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "limit = 20 # The number of key terms to display\n",
    "\n",
    "display(HTML('<h4>Terms Characteristic of This Corpus:</h4>'))\n",
    "terms = ', '.join(list(corpus.get_scaled_f_scores_vs_background().index[:limit]))\n",
    "display(HTML('<p>' + terms + '</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate terms associated with a field value\n",
    "\n",
    "For the `score_query` configuration, supply one of the row values in the Counts Report above. The `score_label` can be a more human-readable or descriptive label for the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "limit = 20 # The number of key terms to display\n",
    "score_query = '' # The column value to query, e.g. 'US private college'\n",
    "score_label = '' # The label to give the query results -- can be the same or a more descriptive label\n",
    "\n",
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df[score_label] = corpus.get_scaled_f_scores(score_query)\n",
    "display(HTML('<h4>Key Terms Associated with \"' + score_label + '\":</h4>'))\n",
    "terms = ', '.join(list(term_freq_df.sort_values(by=score_label, ascending=False).index[:limit]))\n",
    "display(HTML('<p>' + terms + ':</p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Scattertext Visualization of Term Associations\n",
    "\n",
    "This cell generates a Scattertext visualization, which is saved at the location you specify for `filename`. Be sure to set `limit` to the same number you used for generating the corpus.\n",
    "\n",
    "The `field_name` value should be taken from one of the row values in the Counts Report above. In the graph, the axis for this field will be labelled with the value you provide for `field_label`. The other access will be labelled by the value you provide for `non_field_label`. You can also modify the width of the graph and supply an extra metadata category, which will be the name of a column in the Documents table above. The values for that category will be displayed above sample documents in the graph.\n",
    "\n",
    "The results can be filtered by minimum term frequency and pointwise mutual information (the higher the number the greater the requirement that terms co-occur in the same document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "filename                   = '' # E.g. 'US-private-college_test.html'\n",
    "limit                      = 2000 # Less than or equal to the `limit` value used to build the corpus\n",
    "field                      = '' # E.g. 'US private college'\n",
    "field_label                = '' # A more descriptive label for the field\n",
    "non_field_label            = '' # E.g. 'non-US private college'\n",
    "width_in_pixels            = 1000\n",
    "extra_metadata             = 'date'\n",
    "minimum_term_frequency     = 0\n",
    "pmi_threshold_coefficient  = 0\n",
    "\n",
    "# Generate and save the html file\n",
    "html = st.produce_scattertext_explorer(corpus, category=field, category_name=field_label, not_category_name=non_field_label,\n",
    "                                       width_in_pixels=width_in_pixels, metadata=corpus.get_df()[extra_metadata].head(limit),\n",
    "                                       minimum_term_frequency=minimum_term_frequency,\n",
    "                                       pmi_threshold_coefficient=pmi_threshold_coefficient)\n",
    "open(filename, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "# Display the link\n",
    "current_dir = %pwd\n",
    "project_dir = str(Path(current_dir).parent.parent)\n",
    "config_path = project_dir + '/config/config.py'\n",
    "%run {config_path}\n",
    "%run {scattertext_script_path}\n",
    "display_link(filename, project_dir, WRITE_DIR, PORT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
