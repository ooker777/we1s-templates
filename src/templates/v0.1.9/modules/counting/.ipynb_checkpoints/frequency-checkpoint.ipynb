{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Frequencies of Ngrams within a Document or Project \n",
    "\n",
    "This notebook provides methods for calculating raw and/or relative frequency values for ngrams (uni-, bi-, and/or trigrams are accepted) within a single document or across all of the project's documents. If you run cells in the notebook the first time counting unigrams, you must reconfigure your code in **Section 1** and re-run code in **Section 2** and **Section 3** to calculate and explore these frequencies. \n",
    "\n",
    "### Technical Note\n",
    "\n",
    "This notebook uses the NLTK package to build a custom tokenizer to tokenize project uni-, bi-, and trigrams. This tokenizer differs from the one used in the WE1S preprocessing pipeline. See the module's <a href=\"README.md\" target=\"_blank\">README.md</a> file for more information.\n",
    "\n",
    "### INFO\n",
    "\n",
    "__author__    = 'Lindsay Thomas'  \n",
    "__copyright__ = 'copyright 2020, The WE1S Project'  \n",
    "__license__   = 'MIT'  \n",
    "__version__   = '2.0'  \n",
    "__email__     = 'lindsaythomas@miami.edu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Import scripts\n",
    "%run scripts/count_tokens.py\n",
    "\n",
    "# Define paths\n",
    "current_dir     = %pwd\n",
    "current_pathobj = Path(current_dir)\n",
    "project_dir     = str(current_pathobj.parent.parent)\n",
    "project_name    = os.path.basename(project_dir)\n",
    "current_reldir  = current_dir.split(\"/write/\")[1]\n",
    "data_dir        = project_dir + '/project_data'\n",
    "json_dir        = project_dir + '/project_data/json'\n",
    "stopword_file   = '/home/jovyan/write/pub/templates/project_template/modules/topic_modeling/scripts/we1s_standard_stoplist.txt'\n",
    "\n",
    "display(HTML('<p style=\"color: green;\"><strong>Setup complete.</strong></p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Code\n",
    "\n",
    "You must run all of the cells in this \"Configure Code\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Data Source\n",
    "\n",
    "If you wish to use a single document, enter **the full path** to the document for the `fpath` configuration below: e.g. `fpath='foo/bar/project_name/project_data/json/document.json'`. If you leave it blank (or set it to `None`) the contents of the project's `json` directory will be used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure filepath\n",
    "fpath = ''\n",
    "\n",
    "# If using a single file, define the path; otherwise the entire json directory will be used\n",
    "if fpath == '' or fpath is None:\n",
    "    mode = 'dir'\n",
    "    display(HTML('<p style=\"color: green;\">You have selected the entire <code>json</code> directory as your data source.</p>'))\n",
    "else:\n",
    "    mode = 'file'\n",
    "    display(HTML('<p style=\"color: green;\">You have selected <code>' + fpath + '</code> as your data source</p>.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Content Field\n",
    "\n",
    "In this cell, you will configure which field you would like to use as your input using the `content_field` variable. If your data includes full-text data in the `content` field, you can set `content_field = 'content'`. If you want to calculate frequency values using data in your `bag_of_words` field, set `content_field = 'bag_of_words'`. If you want to use the `features` field, set `content_field = 'features'`. Follow this format exactly (including the quotation marks).\n",
    "\n",
    "**Please note that if you use EITHER `bag_of_words` OR `features` as your text input field, you will only be able to count unigrams. See the module's <a href=\"README.md\" target=\"_blank\">README.md</a> file for more information on these fields.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may select 'content', 'features', or 'bag_of_words'\n",
    "content_field = 'content'\n",
    "\n",
    "if content_field not in ['content', 'features', 'bag_of_words']:\n",
    "    msg = \"The <code>content_field</code> variable must be 'content', 'features', or 'bag_of_words'.\"\n",
    "    display(HTML('<p style=\"color: red;\">' + msg + '</p>.'))\n",
    "else:\n",
    "    msg = 'You have set the <code>content_field</code> variable to <code>' + content_field + '</code>.'\n",
    "    display(HTML('<p style=\"color: green;\">' + msg + '</p>.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Tokenization Length\n",
    "Configure the `set_length` variable below according to the length of ngram you are obtaining frequency counts for. The default is unigrams; to count bigrams or trigrams, comment out the unigram line, and uncomment the bi- or trigram line. \n",
    "\n",
    "**Note:** Because this code does not strip hyphens, hyphenated words like \"first-generation\" are considered unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose to analyze unigrams, bigrams, or trigrams\n",
    "set_length = 'unigram'\n",
    "# set_length = 'bigram'\n",
    "# set_length = 'trigram'\n",
    "\n",
    "\n",
    "if set_length not in ['unigram', 'bigram', 'trigram']:\n",
    "    display(HTML(\"<p style=\\\"color: red;\\\">The <code>set_length</code> variable must be 'unigram', 'bigram', or 'trigram'.</p>\"))\n",
    "elif (set_length == 'bigram' or set_length == 'trigram' and content_field == 'bag_of_words') or (set_length == 'bigram' or set_length == 'trigram' and content_field == 'features'):\n",
    "    msg = 'You cannot search for ' + set_length + 's with selected content field.'\n",
    "    display(HTML('<p style=\"color: red;\">' + msg + '</p>'))\n",
    "else:\n",
    "    msg = 'You have set the <code>set_length</code> variable to <code>' + set_length + '</code>.'\n",
    "    display(HTML('<p style=\"color: green;\">' + msg + '</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Punctuation Setting\n",
    "\n",
    "This cell strips common punctuation from project documents. It will **NOT** strip hyphens, single or double, in order to account for hyphenated words and phrases such as \"first-generation\". Because this punctuation list is bespoke and not standardized (standardized options strip hyphens), some punctuation marks or other non-Unicode characters may make it through. You do not need to change anything about the below cell (unless you are interested in the frequency of punctuation marks, or @ signs, etc.), but you do need to run it. If you do not want to remove punctuation from your documents, you should set the `punctuations` variable to an empty string by uncommenting the line that says `punctuations = ''` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define punctuation to strip\n",
    "punctuations = \"_______________________\\'m\\'n\\'ve!()[]{};:\\'\\\"\\,<>./?@#$%^&*_~''``''\"\n",
    "\n",
    "# To strip no punctuation, uncomment the line below\n",
    "# punctuations = ''\n",
    "\n",
    "if punctuations == '':\n",
    "    display(HTML('<p style=\"color: red;\">You have elected not to strip any punctuation.</p>'))\n",
    "else:\n",
    "    msg = 'You have set the <code>punctuations</code> variable to <code>' + punctuations + '</code>.'\n",
    "    display(HTML('<p style=\"color: green;\">' + msg + '</p>'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Stop Word Setting\n",
    "\n",
    "The default setting is to delete stop words before obtaining word frequencies using the WE1S standard stoplist. You can view this list in you project's `modules/topic_modeling/scripts` folder. You can edit this file for your project or create a custom stoplist. If you use a custom list, make sure that it is a plain text file with one word per line. Upload the file to your project and configure the `stopword_file` variable in the **Settings** cell to indicate the path to your custom stop word file.\n",
    "\n",
    "If your data has already had the stop words you want removed or if you do not want to remove stop words, change the value of `set_stopwords` to `False`.\n",
    "\n",
    "It is generally recommended to delete stop words from a document before obtaining bi- and/or trigram frequencies. This will result in \"inexact\" bi- and trigrams, however, as any stop words will be deleted *before* tokenization into bi- or trigrams. If you are interested in specific bi- or trigrams that contain stop words, such as \"first\" in \"first generation\" (without a hyphen), you may want to create a custom stop word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete stopwords from content fields before obtaining word frequencies.\n",
    "# If set to True, stop words will be deleted. If set to false, stop words will not be deleted.\n",
    "set_stopwords = True\n",
    "\n",
    "if set_stopwords == True:\n",
    "    display(HTML('<p style=\"color: green;\">You have elected to strip stopwords.</p>'))\n",
    "else:\n",
    "    display(HTML('<p style=\"color: red;\">You have elected not to strip stopwords.</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Frequencies\n",
    "\n",
    "Run the code below to calculate token frequencies. If you are calculating frequency values for all documents in your project, this may take awhile depending on the number of documents in your project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequencies for the project as a whole\n",
    "if mode == 'dir':\n",
    "    try:\n",
    "        all_finders_freq, all_finders_list, freq, bad_jsons = frequency_dir(json_dir, content_field, set_stopwords, \n",
    "                                                                            punctuations, set_length, stopword_file)\n",
    "        if len(bad_jsons) > 0:\n",
    "            msg = 'Warning! ' + str(len(bad_jsons)) + ' documents failed to load and will not be included in the counting. '\n",
    "            msg += 'If this number is large, this will significantly affect your results.'\n",
    "            display(HTML('<p style=\"color: red;\">' + msg + '</p>'))\n",
    "        display(HTML('<p style=\"color: green;\">Frequency counts complete. View and explore results by running the cells below.</p>'))\n",
    "    except NameError:\n",
    "        display(HTML('<p style=\"color: red;\">You have not configured all required variables. Please complete <strong>Section 1</strong>.</p>'))    \n",
    "# Calculate frequencies for a single file\n",
    "if mode == 'file':\n",
    "    try:\n",
    "        finder, freq = frequency_single_file(fpath, content_field, set_stopwords, punctuations, set_length, stopword_file)\n",
    "    except NameError:\n",
    "        display(HTML('<p style=\"color: red;\">You have not configured all required variables. Please complete <strong>Section 1</strong>.</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore and Visualize Results\n",
    "\n",
    "In this section, you can create and view dataframes listing the most frequent words by raw and relative frequency values; you can plot the most frequent tokens in your document or project; and/or you can find the raw or relative frequency value of a specific token in your document or project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce and View a Dataframe of Raw or Relative Frequency Counts \n",
    "\n",
    "Produce a dataframe of the raw or relative frequency values in your project or document. The dataframe will be ordered by count, from the tokens with the highest frequency value to those with the lowest. You can re-run the cells below to obtain both the raw and the relative frequency values for your project or document (i.e., you don't have to re-run section 2 if you want to explore relative frequency values instead of raw, for example). All other cells in this section of the notebook require you to have run the below two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 'raw' or 'relative' frequency\n",
    "# freq_type = 'raw'\n",
    "freq_type = 'relative'\n",
    "display(HTML('<p style=\"color:green;\">You have set the <code>freq_type</code> variable to <code>' + freq_type + '</code>.</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe and frequency distribution\n",
    "df, freq_dist = freq_df(freq_type, freq)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell uses a <a href=\"https://github.com/quantopian/qgrid\" target=\"_blank\">QGrid</a> widget to display count results in a dataframe. Click a column label to sort by that column. Click it again to reverse sort. Click the filter icon to the right of the column label to apply filters (for instance, reducing the table to only documents from specific sources). You can re-order the columns by dragging the column label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "qgrid_widget = qgrid.show_grid(df, show_toolbar=False)\n",
    "\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Dataframe to a CSV File\n",
    "\n",
    "The cells below will save the version of the dataframe you see displayed in the cell above. To save the full version of the dataframe (disregarding any filtering, etc you have done in the qgrid dataframe), skip the second cell below, uncomment the code in the cell below it, and run that cell. \n",
    "\n",
    "First, provide a name for the csv file the below code will create by providing a filename in the `csv_file` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The filename of the csv file the below code will create\n",
    "csv_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save version of dataframe you see above to csv\n",
    "changed_df = qgrid_widget.get_changed_df()\n",
    "\n",
    "changed_df.to_csv(csv_file_counts, index_label = 'Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the above dataframe to a csv file\n",
    "# df_frequencies.to_csv(csv_file_counts, index_label = 'Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Top N Tokens and their Raw or Relative Frequency Values \n",
    "\n",
    "We don't recommend you plot a graph of *all* token frequencies in a document or a project, as it will be hard to read. Instead, define the top number you want to see (i.e., the top 30 results), and plot those. The default number of top tokens to plot is 30. If you would like to change this, please change the value of the `top_n` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of top results you want to see in your plot\n",
    "top_n = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot frequency values\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot top n words by raw and relative frequency\n",
    "try:\n",
    "    if freq_type not in ['raw', 'relative']:\n",
    "        display(HTML('<p style=\"color: red;\">You need to set the <code>freq_type</code> variable to <code>raw</code> or <code>relative</code>.'))\n",
    "except NameError:\n",
    "    display(HTML('<p style=\"color: red;\">You need to set the <code>freq_type</code> variable to <code>raw</code> or <code>relative</code>.'))\n",
    "if freq_type == 'raw':\n",
    "    freq.plot(top_n, title = 'Raw Frequencies')\n",
    "if freq_type == 'relative':\n",
    "    freq_dist.plot(top_n, title = 'Relative Frequencies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the Raw or Relative Frequency Value of a Specific Token in your Project\n",
    "\n",
    "Before you perform the analysis, run the cell below to check the value of the `set_length` variable to make sure you have tokenized on the proper token length. I.e., if you are searching for a specific word, you need to have tokenized on unigrams above in **Section 2**. If you ran the function using the unigram setting, but would now like to search for a bigram or trigram, you must reconfigure the code in **Section 1** of this notebook and re-calculate frequency values in **Section 2**. \n",
    "\n",
    "The cell below will also check the value of the `freq_type` variable you set earlier in this section. If you are exploring raw frequency values, the value for the specific word will display as a number. If you are exploring relative frequency values, it will display as a percentage (but in decimal form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'You have set the <code>set_length</code> variable to <code>' + set_length + '</code>.'\n",
    "display(HTML('<p style=\"color: green;\">'+ msg + '</p>'))\n",
    "msg = 'You have set the <code>freq_type</code> variable to <code>' + freq_type + '</code>.'\n",
    "display(HTML('<p style=\"color: green;\">' + msg + '</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the token you want to search for. If you are searching for a unigram, just enter it below. The tokenization method used in this notebook is case-insensitive (i.e., it is not possible to differentiate between \"book\" and \"Book\"). If you are searching for a specific bigram or trigram, enter it with spaces separating each part. Remember that if you deleted stopwords above, your bi- or trigram should not contain stopwords. Follow the below format exactly:\n",
    "\n",
    "`token = 'unigram'`\n",
    "\n",
    "OR\n",
    "\n",
    "`token = 'bigram example'`\n",
    "\n",
    "OR\n",
    "\n",
    "`token = 'trigram example here'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure token\n",
    "token = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell to obtain the frequency count for your selected token. If your token as it is entered above does not appear in the document or documents analyzed, the frequency count will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frequency count\n",
    "freq_token(token, set_length, freq_type, freq, freq_dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
